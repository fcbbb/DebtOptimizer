import json
import logging
import asyncio
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.layers import get_channel_layer
from asgiref.sync import async_to_sync
from .llm_use.llm_chat import get_llm_response
from .llm_use.llm_database import get_llm_response_database
from .llm_use.llm_agent import get_llm_response_agent

logger = logging.getLogger(__name__)

class ChatConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        try:
            self.task_id = self.scope['url_route']['kwargs']['task_id']
            self.room_group_name = f'chat_{self.task_id}'
            
            # Join room group
            await self.channel_layer.group_add(
                self.room_group_name,
                self.channel_name
            )
            
            await self.accept()
        except Exception as e:
            # å¯é€‰ï¼šä¸»åŠ¨å…³é—­
            await self.close()

    async def disconnect(self, close_code):
        # Leave room group
        await self.channel_layer.group_discard(
            self.room_group_name,
            self.channel_name
        )
        logger.info(f"WebSocket disconnected for task {self.task_id}")

    # æ¥å— WebSocket æ¶ˆæ¯
    async def receive(self, text_data):
        try:
            data = json.loads(text_data)
            # ä»å‰ç«¯å‘é€çš„æ•°æ®ä¸­è·å–contentå­—æ®µï¼Œè€Œä¸æ˜¯messageå­—æ®µ
            message = data.get('content')
            conversation_id = data.get('conversation_id')
            message_type = data.get('type')
            
            if message:
                # Send message to room group
                # å‘é€æ¶ˆæ¯åˆ°æˆ¿é—´ç»„ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºæˆ‘ä»¬éœ€è¦å°†ç”¨æˆ·å‘é€çš„æ¶ˆæ¯å¹¿æ’­ç»™æ‰€æœ‰è¿æ¥åˆ°è¯¥æˆ¿é—´ç»„çš„å®¢æˆ·ç«¯ï¼ˆåŒ…æ‹¬å‰ç«¯ï¼‰
                # æ¶ˆæ¯åˆ†å‘æ–¹æ³•ï¼ˆäº‹ä»¶å¤„ç†å™¨ï¼‰ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºæˆ‘ä»¬éœ€è¦æ ¹æ®ç”¨æˆ·å‘é€çš„æ¶ˆæ¯ç±»å‹ï¼Œè°ƒç”¨ä¸åŒçš„äº‹ä»¶å¤„ç†å™¨æ¥å¤„ç†æ¶ˆæ¯
                await self.channel_layer.group_send(
                    self.room_group_name,
                    {
                        'type': 'chat.message', # å‰ç«¯å‘é€çš„æ¶ˆæ¯ç±»å‹
                        'message': message, # å‰ç«¯å‘é€çš„æ¶ˆæ¯å†…å®¹
                        'sender': 'user', # å‰ç«¯å‘é€çš„æ¶ˆæ¯å‘é€è€…
                        'conversation_id': conversation_id # å‰ç«¯å‘é€çš„æ¶ˆæ¯æ‰€å±çš„å¯¹è¯ID
                    }
                )
                
                # Process the request and get AI response with streaming
                # å¤„ç†ç”¨æˆ·è¯·æ±‚å¹¶è·å–AIå“åº”ï¼ˆæµå¼ï¼‰
                # await self.process_request(message)
                # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šå¯åŠ¨åå°ä»»åŠ¡ï¼Œä¸è¦ awaitï¼
                asyncio.create_task(self.process_request(message, conversation_id))
        except json.JSONDecodeError:
            await self.send(text_data=json.dumps({
                'type': 'error',
                'message': 'Invalid JSON format'
            }))

    async def process_request(self, message, conversation_id):
        """
        Process the user request and return AI response with streaming
        """
        # æ„å»ºæç¤ºè¯
        # æ„å»ºæç¤ºè¯ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºæˆ‘ä»¬éœ€è¦æ ¹æ®ç”¨æˆ·å‘é€çš„æ¶ˆæ¯æ„å»ºä¸€ä¸ªæç¤ºè¯ï¼Œä»¥ä¾¿LLMèƒ½å¤Ÿç†è§£ç”¨æˆ·çš„æ„å›¾
        prompt = self.build_prompt(message)
        
        # Send typing indicator
        # å‘é€æ€è€ƒæŒ‡ç¤ºå™¨ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºæˆ‘ä»¬éœ€è¦å‘Šè¯‰å‰ç«¯ç”¨æˆ·æ­£åœ¨æ€è€ƒä¸­ï¼Œä»¥ä¾¿ç”¨æˆ·çŸ¥é“æœåŠ¡å™¨æ­£åœ¨å¤„ç†è¯·æ±‚
    
        # === é˜¶æ®µ 1: åˆ†æå€ºåŠ¡ ===
        await self.channel_layer.group_send(
            self.room_group_name,
            {
                'type': 'chat.thinking',
                'content': 'æ­£åœ¨åˆ†ææ‚¨çš„å€ºåŠ¡æƒ…å†µ...',
                'sender': 'system'
            }
        )
        # æ¨¡æ‹ŸçŸ­å»¶è¿Ÿï¼ˆå¯é€‰ï¼Œæå‡æ„ŸçŸ¥ï¼‰
        await asyncio.sleep(0.5)

        # === é˜¶æ®µ 2: ç”Ÿæˆå»ºè®® ===
        await self.channel_layer.group_send(
            self.room_group_name,
            {
                'type': 'chat.thinking',
                'content': 'æ­£åœ¨ç”Ÿæˆä¸ªæ€§åŒ–è¿˜æ¬¾å»ºè®®...',
                'sender': 'system'
            }
        )
        await asyncio.sleep(0.3)

        # === é˜¶æ®µ 3: è°ƒç”¨ LLM æµå¼å“åº” ===
        try:
            # full_response = ""
            # print(f"å¼€å§‹å¤„ç†è¯·æ±‚ï¼Œè°ƒç”¨ LLM æµå¼å“åº”ï¼Œæç¤ºè¯: {prompt}ï¼Œä¼šè¯ID: {conversation_id}")
            
            # async for chunk in get_llm_response_agent(prompt, conversation_id):
            #     full_response += chunk
            #     await self.channel_layer.group_send(
            #         self.room_group_name,
            #         {
            #             'type': 'chat.message_chunk',
            #             'chunk': chunk,
            #             'sender': 'ai'
            #         }
            #     )
            
            
            await self.channel_layer.group_send(
                self.room_group_name,
                {
                    'type': 'chat.message_complete',
                    'message': full_response,
                    'sender': 'ai'
                }
            )
        except Exception as e:
            error_msg = f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"
            await self.channel_layer.group_send(
                self.room_group_name,
                {
                    'type': 'chat.error',
                    'message': error_msg,
                    'sender': 'system'
                }
            )
        finally:
            # å¯é€‰ï¼šå‘é€ç»“æŸä¿¡å·ï¼ˆå‰ç«¯å·²ç”¨ response_endï¼Œå¯çœç•¥ï¼‰
            pass

    # === æ–°å¢/ä¿®æ­£äº‹ä»¶å¤„ç†å™¨ ===

    async def chat_thinking(self, event):
        """å¤„ç† 'thinking' ç±»å‹æ¶ˆæ¯"""
        await self.send(text_data=json.dumps({
            'type': 'thinking',
            'content': event['content'],
            'sender': event.get('sender', 'system')
        }))

    async def chat_message(self, event):
        """ç°åœ¨ç”¨äºå¹¿æ’­ç”¨æˆ·æ¶ˆæ¯ï¼ˆé errorï¼‰"""
        await self.send(text_data=json.dumps({
            'type': 'user_message',  # æˆ–ä¿ç•™ä¸º 'chat_message'ï¼Œä½†å‰ç«¯éœ€ç›‘å¬
            'content': event['message'],
            'sender': event.get('sender', 'user'),
            'conversation_id': event.get('conversation_id')
        }))

    async def chat_error(self, event):
        """ä¸“ç”¨é”™è¯¯å¤„ç†å™¨"""
        await self.send(text_data=json.dumps({
            'type': 'error',
            'message': event['message'],
            'sender': event.get('sender', 'system')
        }))

# æ³¨æ„ï¼šä¿ç•™åŸæœ‰çš„ chat_message_chunk / chat_message_complete / chat_typing
# ä½† chat_typing ç›®å‰æœªè¢«å‰ç«¯ä½¿ç”¨ï¼Œå¯è€ƒè™‘ç§»é™¤æˆ–ç”¨äºå…¶ä»–ç”¨é€”
    
    async def chat_message_chunk(self, event):
        # Send message chunk to WebSocket
        await self.send(text_data=json.dumps({
            'type': 'response_chunk',
            'content': event['chunk'],
            'sender': event.get('sender', 'ai')
        }))

    async def chat_message_complete(self, event):
        # Send complete message to WebSocket
        await self.send(text_data=json.dumps({
            'type': 'response_end',
            'content': event['message'],
            'sender': event.get('sender', 'ai')
        }))

    async def chat_typing(self, event):
        # Send typing indicator to WebSocket
        await self.send(text_data=json.dumps({
            'type': 'start_thinking',
            'is_typing': event['is_typing']
        }))
        
    def build_prompt(self, message):
        """
        Build the prompt for the LLM based on the user message
        """
        return f"ç”¨æˆ·æ¶ˆæ¯: {message}\n"