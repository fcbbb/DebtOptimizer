import os
import logging
from functools import lru_cache
from dotenv import load_dotenv
from langchain.agents import create_agent
from langchain_core.messages import ToolMessage
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SQLDatabase
from langchain.tools import tool
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langgraph.checkpoint.memory import InMemorySaver  


# åˆ›å»ºç¼“å­˜å­—å…¸ç”¨äºå­˜å‚¨å¸¸è§é—®é¢˜çš„ç­”æ¡ˆ
common_questions_cache = {}

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
db_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'db.sqlite3')
db = SQLDatabase.from_uri(f"sqlite:///{db_path}")


model = ChatOpenAI(
    model="qwen-max",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    temperature=0.1,  # æ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶æ¨¡å‹çš„éšæœºç¨‹åº¦ï¼Œé»˜è®¤å€¼ä¸º0.1
    max_tokens=1000,  # æœ€å¤§è¾“å‡ºtokenæ•°ï¼Œé»˜è®¤å€¼ä¸º1000
    timeout=30,  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’ï¼Œé»˜è®¤å€¼ä¸º30
    max_retries=2,  # æœ€å¤§é‡è¯•æ¬¡æ•°
    # ... (other params)
)

toolkit = SQLDatabaseToolkit(db=db, llm=model)

tools_sql = toolkit.get_tools()

# åˆ›å»ºå¤šä¸ªå·¥å…·
@tool(description="ç”¨äºå›ç­”ä¸æ•°æ®åº“æ— å…³çš„é€šç”¨é—®é¢˜ï¼Œå¦‚è§£é‡Šä¸šåŠ¡æµç¨‹ã€å®šä¹‰æœ¯è¯­ã€æä¾›å¸®åŠ©ç­‰ã€‚")
def answer_general_question(question: str) -> str:
    """
    å›ç­”ä¸æ•°æ®åº“æ— å…³çš„é€šç”¨é—®é¢˜
    :param question: ç”¨æˆ·çš„é—®é¢˜
    :return: å¤§æ¨¡å‹ç”Ÿæˆçš„å›ç­”
    """
    try:
        # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦å·²æœ‰ç­”æ¡ˆ
        if question in common_questions_cache:
            return common_questions_cache[question]
        
        # æ„é€ ä¸“é—¨ç”¨äºå›ç­”é€šç”¨é—®é¢˜çš„æç¤ºè¯
        general_prompt = f"""
                        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸šåŠ¡åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”ä»¥ä¸‹é—®é¢˜ã€‚
                        æä¾›å‡†ç¡®ã€ç®€æ´ä¸”æœ‰å¸®åŠ©çš„å›ç­”ã€‚
                        å¦‚æœé—®é¢˜æ¶‰åŠå…·ä½“å®¢æˆ·æ•°æ®ã€è´¦å•ä¿¡æ¯ç­‰ï¼Œè¯·è¯´æ˜éœ€è¦é€šè¿‡æ•°æ®åº“æŸ¥è¯¢è·å–ã€‚
                        å¦‚æœä¸ç¡®å®šç­”æ¡ˆï¼Œè¯·è¯šå®è¯´æ˜ã€‚

                        é—®é¢˜ï¼š{question}

                        è¯·å›ç­”ï¼š
                        """
        
        # è°ƒç”¨å¤§æ¨¡å‹è·å–å›ç­”ï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
        response = model.invoke(
            [{"role": "user", "content": general_prompt}],
            timeout=30  # è®¾ç½®30ç§’è¶…æ—¶
        )

        # è¿”å›æ¨¡å‹çš„å›ç­”
        if hasattr(response, 'content'):
            result = response.content
        else:
            result = str(response)
            
        # å°†ç»“æœå­˜å…¥ç¼“å­˜
        common_questions_cache[question] = result
        return result
    except Exception as e:
        # å¦‚æœå‡ºç°é”™è¯¯ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
        error_msg = f"æŠ±æ­‰ï¼Œå›ç­”é—®é¢˜æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
        return error_msg


def handle_tool_errors(request, handler):
    """å¤„ç†å·¥å…·æ‰§è¡Œé”™è¯¯ï¼Œè¿”å›è‡ªå®šä¹‰é”™è¯¯æ¶ˆæ¯ã€‚"""
    try:
        return handler(request)
    except Exception as e:
        # è¿”å›ä¸€ä¸ªè‡ªå®šä¹‰é”™è¯¯æ¶ˆæ¯ç»™æ¨¡å‹
        return ToolMessage(
            content=f"å·¥å…·æ‰§è¡Œé”™è¯¯ï¼šè¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥å¹¶é‡è¯•ã€‚({str(e)})",
            # è¿”å›é”™è¯¯æ¶ˆæ¯ç»™æ¨¡å‹ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨ID
            tool_call_id=request.tool_call["id"]
        )


# å®šä¹‰ç³»ç»Ÿæç¤ºï¼ˆå¢å¼ºåˆ¤æ–­èƒ½åŠ›ï¼‰
# ç³»ç»Ÿæç¤ºï¼šå¼•å¯¼ LLM æ­£ç¡®ä½¿ç”¨å·¥å…·ï¼ˆå°¤å…¶å¼ºè°ƒ query_checker å’Œ schemaï¼‰
system_prompt = """
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä¸šåŠ¡åŠ©æ‰‹ï¼Œå¯ä»¥æŸ¥è¯¢å…¬å¸æ•°æ®åº“æˆ–å›ç­”é€šç”¨é—®é¢˜ã€‚

ğŸ“Œ é‡è¦ä¸šåŠ¡å®šä¹‰ï¼š
- â€œè´¢åŠ¡çŠ¶å†µâ€æŒ‡å®¢æˆ·çš„ä»¥ä¸‹ä¿¡æ¯ç»„åˆï¼š
  â€¢ ä¿¡ç”¨å¡æ€»æˆä¿¡é¢åº¦ï¼ˆcore_creditcard.total_limitï¼‰
  â€¢ è´·æ¬¾ä½™é¢ï¼ˆcore_loan.balanceï¼‰
- â€œå®¢æˆ·ä¿¡æ¯â€åŒ…æ‹¬ï¼šå§“åã€ç”µè¯ã€èèµ„æ—¥æœŸã€ç­¾çº¦æ—¥æœŸç­‰ï¼ˆæ¥è‡ª core_customerï¼‰

å¯ç”¨å·¥å…·ï¼š
- sql_db_list_tables: è·å–æ‰€æœ‰è¡¨åï¼ˆè¾“å…¥ï¼šç©ºå­—ç¬¦ä¸²ï¼‰
- sql_db_schema: æŸ¥çœ‹è¡¨ç»“æ„ï¼ˆè¾“å…¥ï¼šè¡¨åï¼Œå¦‚ "core_customer"ï¼‰
- sql_db_query: æ‰§è¡Œ SELECT æŸ¥è¯¢ï¼ˆä»…é™ SELECTï¼Œè¾“å…¥ï¼šåˆæ³• SQLï¼‰
# æ–°å¢æˆ–å¼ºè°ƒï¼š
**âš ï¸ è­¦å‘Šï¼šç”Ÿæˆçš„ SQL è¯­å¥åœ¨ JSON å­—ç¬¦ä¸²å†…ï¼Œç»å¯¹ä¸èƒ½ä»¥åˆ†å· (;) ç»“å°¾ã€‚**
- answer_general_question: å›ç­”éæ•°æ®é—®é¢˜ï¼ˆå¦‚è§£é‡Šæœ¯è¯­ã€æµç¨‹ï¼‰

å·¥å…·é€‰æ‹©è§„åˆ™ï¼š
1. å½“é—®é¢˜æ¶‰åŠå…·ä½“å®¢æˆ·ã€é‡‘é¢ã€æ—¥æœŸã€è´¦å•ç­‰ â†’ ä½¿ç”¨ SQL å·¥å…·ã€‚
   - ç¤ºä¾‹ï¼šâ€œå¼ ä¸‰çš„è´¢åŠ¡çŠ¶å†µï¼Ÿâ€ â†’ æŸ¥è¯¢ core_customer, core_creditcard, core_loan ç›¸å…³å­—æ®µ
2. å½“é—®é¢˜æ— æ³•è½¬åŒ–ä¸ºå…·ä½“å­—æ®µï¼ˆå¦‚â€œä»–æœ‰é’±å—ï¼Ÿâ€ï¼‰â†’ ä½¿ç”¨ answer_general_question è§£é‡Šé™åˆ¶ã€‚
3. å¦‚æœ SQL æŸ¥è¯¢å¤±è´¥ï¼ˆå¦‚å­—æ®µä¸å­˜åœ¨ï¼‰â†’ å…ˆç”¨ sql_db_schema ç¡®è®¤ç»“æ„ï¼Œæˆ–è½¬ä¸ºé€šç”¨å›ç­”ã€‚
4. æ‰€æœ‰è¡¨åå¿…é¡»å¸¦ 'core_' å‰ç¼€ã€‚
5. å›ç­”å¿…é¡»ç”¨ä¸­æ–‡ï¼Œç®€æ´æ˜äº†ã€‚å¦‚æœæ•°æ®ç¼ºå¤±ï¼Œæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ã€‚
6. å¯¹äºå®¢æˆ·è´¢åŠ¡çŠ¶å†µæŸ¥è¯¢ï¼Œéœ€è¦å…³è”å¤šä¸ªè¡¨ï¼š
   - é¦–å…ˆç¡®è®¤å®¢æˆ·æ˜¯å¦å­˜åœ¨ï¼šSELECT * FROM core_customer WHERE name = 'å®¢æˆ·å'
   - ç„¶åå…³è”æŸ¥è¯¢ç›¸å…³ä¿¡æ¯ï¼š
     * core_customer: å®¢æˆ·åŸºæœ¬ä¿¡æ¯
     * core_loan: å®¢æˆ·è´·æ¬¾ä¿¡æ¯
     * core_creditcard: å®¢æˆ·ä¿¡ç”¨å¡ä¿¡æ¯
     * core_monthlypayment: å®¢æˆ·æœˆä¾›ä¿¡æ¯
7. å¦‚æœæŸ¥è¯¢ä¸åˆ°å®¢æˆ·ä¿¡æ¯ï¼Œåº”æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·è¯¥å®¢æˆ·ä¸å­˜åœ¨ã€‚

ç¤ºä¾‹ï¼š
- é—®ï¼šâ€œæå››çš„è´¢åŠ¡çŠ¶å†µï¼Ÿâ€ â†’ ç”Ÿæˆ JOIN æŸ¥è¯¢ï¼Œè·å–å®¢æˆ·ã€ä¿¡ç”¨å¡ã€è´·æ¬¾ä¿¡æ¯
- é—®ï¼šâ€œèèµ„æ—¥æœŸæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿâ€ â†’ è°ƒç”¨ answer_general_question
- é—®ï¼šâ€œæ€ä¹ˆè¯„ä¼°å®¢æˆ·é£é™©ï¼Ÿâ€ â†’ è°ƒç”¨ answer_general_questionï¼Œè§£é‡Šéœ€ç»“åˆå¤šç»´åº¦
- é—®ï¼šâ€œæç€šæ–‡çš„è´¢åŠ¡çŠ¶å†µæ€ä¹ˆæ ·ï¼Ÿâ€ â†’ å…ˆæŸ¥è¯¢core_customerè¡¨ç¡®è®¤å®¢æˆ·å­˜åœ¨ï¼Œå†å…³è”å…¶ä»–è¡¨è·å–å®Œæ•´ä¿¡æ¯
"""

# åŠ¨æ€ç³»ç»Ÿæç¤ºï¼ˆæ ¹æ®ç”¨æˆ·è§’è‰²è°ƒæ•´è¡Œä¸ºï¼‰
# @dynamic_prompt
# def user_role_prompt(request: ModelRequest) -> str:
#     """Generate system prompt based on user role."""
#     user_role = request.runtime.context.get("user_role", "user")
#     base_prompt = "You are a helpful assistant."

#     if user_role == "expert":
#         return f"{base_prompt} Provide detailed technical responses."
#     elif user_role == "beginner":
#         return f"{base_prompt} Explain concepts simply and avoid jargon."

#     return base_promp


agent = create_agent(
    model, 
    # å®šä¹‰è¦ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
    tools=[answer_general_question, *tools_sql ],
    # å®šä¹‰ç³»ç»Ÿæç¤ºï¼Œç”¨äºå¼•å¯¼æ¨¡å‹è¡Œä¸º
    system_prompt=system_prompt,
    checkpointer=InMemorySaver(),  
    # checkpointer=MemorySaver()  # å¯é€‰ï¼Œç”¨äºè®°å¿†
    )

async def get_llm_response_agent(prompt, conversation_id):
    """
    è·å–LLMçš„æµå¼å“åº”
    :param prompt: æç¤ºè¯
    :param conversation_id: ä¼šè¯ID
    :return: æµå¼å“åº”ç”Ÿæˆå™¨
    """
    try:
        conversation_id = str(conversation_id)
        
        # ä½¿ç”¨SQL Agentæ‰§è¡ŒæŸ¥è¯¢
        response = agent.invoke(
            {"messages": [{"role": "user", "content": prompt}]},
            {"configurable": {"thread_id": conversation_id}},  
        )
        
        # LangGraph é»˜è®¤è¿”å› {"messages": [...]}
        messages = response.get("messages", [])
        if messages:
            last_message = messages[-1]
            # æœ€ç»ˆå›ç­”é€šå¸¸åœ¨æœ€åä¸€æ¡ AIMessage çš„ content ä¸­
            if hasattr(last_message, 'content'):
                result = str(last_message.content)
                yield result
            else:
                error_msg = "æ— æ³•è§£ææ¨¡å‹å“åº”ã€‚"
                yield error_msg
        else:
            warning_msg = "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            yield warning_msg
    except Exception as e:
        error_msg = f"Error: {str(e)}"
        yield error_msg